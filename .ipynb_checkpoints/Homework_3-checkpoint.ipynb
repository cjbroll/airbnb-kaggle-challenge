{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\"> \n",
    "DATS 6202, Spring 2018, Homework_3\n",
    "</h1> \n",
    "\n",
    "<h1 align=\"center\"> \n",
    "Due April 9, 11:59 PM\n",
    "</h1> \n",
    "\n",
    "<h4 align=\"center\"> \n",
    "Yuxiao Huang ([yuxiaohuang@gwu.edu](mailto:yuxiaohuang@gwu.edu))\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Note\n",
    "- Complete the missing parts indicated by **# Implement me**\n",
    "- Submit an ipynb file named **Homework_3.ipynb** to [blackboard](https://blackboard.gwu.edu) folder /Assignments/Homework_3/\n",
    "-  We expect you to follow a reasonable programming style. While we do not mandate a specific style, we require that your code to be neat, clear, **documented/commented** and above all consistent. **Marks will be deducted if these are not followed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Your friend, E (an engineer), wants to simulate an XOR ($\\oplus$) gate. E googled it and found the solution on [wikipedia](https://en.wikipedia.org/wiki/XOR_gate). It turns out that, an XOR gate can be built using two logic AND ($\\wedge$) gates and one logic OR ($\\vee$) gate:\n",
    "\n",
    "$$x_1 \\oplus x_2 = \\big( x_1 \\wedge \\neg x_2 \\big) \\vee \\big( \\neg x_1 \\wedge x_2 \\big).$$\n",
    "    \n",
    "Here, the XOR gate takes as binary input $x_1$ and $x_2$. The input of one AND gate is comprised of $x_1$ and $\\neg x_2$ (the first parentheses), and that of the other AND gate is composed of $\\neg x_1$ and $x_2$ (the second). The output of the two AND gates is the input of the OR gate.\n",
    "\n",
    "Now the problem becomes to simulate the AND and OR gates. E realized that this is the time to ask help from you, a data scientist. You looked at the problem and found that the AND and OR gates can be simulated using perceptrons (since they are both linearly separable problems). The only challenge is that, you have not learned how to train a sequence of perceptrons yet (i.e., a Neural network). You gazed at the equation above for a while and suddendly had the \"Aha!\" moment. \"It is actually an extremely simple problem because we can train the perceptrons independently!\" you said to E, and started writing a fit function that finds the weights of the three perceptrons. You then went beyond that and wrote a check function that tests whether the weights make sense (so that they can generate the correct output, based on the flow discussed below the equation). After seeing the perfect evaluation scores, E was convinced that this is the simulation he was looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: define the XOR_Gate class\n",
    "1. You must use the sklearn Perceptron classifier (as shown below)\n",
    "2. You cannot use any other classifiers, they are not what your friend E wants\n",
    "3. In order to have the same result, set max_iter=100 for the Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "class XOR_Gate():\n",
    "    \"\"\"The XOR_Gate classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    gates : dictionary\n",
    "      key: 1 to 3, val: gate 1 to 3\n",
    "      \n",
    "    \"\"\"\n",
    "      \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the gates dictionary\"\"\"\n",
    "        self.gates = {}\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit training data.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Implement me\n",
    "        # Hint: some data (based on logic AND and logic OR) should be gerenerated here by calling function get_X123_y123() \n",
    "        data = self.get_X123_y123(X)[-2:]\n",
    "        clf = Perceptron(max_iter = 100)\n",
    "        clf.fit(data[0], data[1])\n",
    "        \n",
    "        self.clf = clf\n",
    "#         return clf\n",
    "        \n",
    "    def print_weights(self, i):\n",
    "        \"\"\"Print the weights of gate i.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        i : integer\n",
    "          The number of the gate\n",
    "       \n",
    "        \"\"\"\n",
    "        \n",
    "        print('------------------------')\n",
    "        print(\"Weights for gate \" + str(i) + ':')\n",
    "        print(\"w0: \" + str(self.gates[i].intercept_))\n",
    "        print(\"w1: \" + str(self.gates[i].coef_[0][0]))\n",
    "        print(\"w2: \" + str(self.gates[i].coef_[0][1]))\n",
    "        print()\n",
    "        \n",
    "    def get_X123_y123(self, X):\n",
    "        \"\"\"Generate data for gates 1 to 3.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Feature vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "          \n",
    "        \"\"\"\n",
    "        \n",
    "        # Data for logic and gate: y1 = (x1) and (not x2)\n",
    "        X1 = np.hstack((X[:, 0].reshape(-1, 1), np.where(X[:, 1], 0, 1).reshape(-1, 1)))\n",
    "        y1 = np.logical_and(X1[:, 0], X1[:, 1])\n",
    "        y1 = np.where(y1, 1, 0)\n",
    "\n",
    "        # Data for logic and gate: y2 = (not x1) and (x2)\n",
    "        X2 = np.hstack((np.where(X[:, 0], 0, 1).reshape(-1, 1), X[:, 1].reshape(-1, 1)))\n",
    "        y2 = np.logical_and(X2[:, 0], X2[:, 1])\n",
    "        y2 = np.where(y2, 1, 0)\n",
    "\n",
    "        # Data for logic or gate: y3 = (y1) or (y2) \n",
    "        X3 = np.hstack((y1.reshape(-1, 1), y2.reshape(-1, 1)))\n",
    "        y3 = np.logical_or(X3[:, 0], X3[:, 1])\n",
    "        y3 = np.where(y3, 1, 0)\n",
    "        \n",
    "        return [X1, y1, X2, y2, X3, y3]\n",
    "        \n",
    "    def check(self, X):\n",
    "        \"\"\"Calculate and print the precision, recall, fscore, and support.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        X: {array-like}, shape = [n_samples, n_features]\n",
    "          Testing vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "          \n",
    "        \"\"\"\n",
    "            \n",
    "        # Implement me\n",
    "        # Hint: some data (based on logic AND and logic OR) should be gerenerated here by calling function get_X123_y123() \n",
    "        \n",
    "        x3, y3 = self.get_X123_y123(X)[-2:]\n",
    "\n",
    "        y3_pred = self.clf.predict(x3)\n",
    "\n",
    "        # Print precision, recall, fscore, and support\n",
    "        print('------------------------')\n",
    "        print('Precision, Recall, Fscore, Supporet: ')\n",
    "        print(precision_recall_fscore_support(y3, y3_pred, average='micro'))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: generate X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X = np.random.randint(2, size=(100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: preprocess data\n",
    "1. randomly choose 30% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Randomly choose 30% of the data for testing\n",
    "X_train, X_test = train_test_split(X, test_size=0.3, random_state=0, stratify=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: train and test the XOR_Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Precision, Recall, Fscore, Supporet: \n",
      "(1.0, 1.0, 1.0, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare the XOR_Gate classifier\n",
    "xor_gate = XOR_Gate()\n",
    "\n",
    "# Train the classifier\n",
    "# Hint: some data (based on logic AND and logic OR) should be gerenerated in the fit function\n",
    "xor_gate.fit(X_train)\n",
    "\n",
    "# Test the classifier\n",
    "xor_gate.check(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference:\n",
    "1. Part of the code is from the \"Python Machine Learning (2nd edition)\" book code repository\n",
    "2. Please find the reference to and website of the book below:\n",
    "    - Raschka S. and Mirjalili V. (2017). Python Machine Learning. 2nd Edition.\n",
    "    - https://sebastianraschka.com/books.html\n",
    "3. Please find the website of the book code repository and info resource below:\n",
    "    - https://github.com/rasbt/python-machine-learning-book-2nd-edition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
